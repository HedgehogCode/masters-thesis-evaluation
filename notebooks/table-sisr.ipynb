{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f364c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from notebooks.utils import *\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEX_TABLE_DIR = \"../masters-thesis-tex/tables/\"\n",
    "\n",
    "MODEL_COL = \"model\"\n",
    "METHOD_COL = \"method\"\n",
    "DATASET_COL = \"dataset\"\n",
    "IMAGE_COL = \"image_index\"\n",
    "SCALE_COL = \"scale_factor\"\n",
    "DOWNSCALE_COL = \"downscale_method\"\n",
    "METRIC_COL = \"metric\"\n",
    "VALUE_COL = \"value\"\n",
    "\n",
    "METHOD_MAPPING = {\n",
    "    \"bicubic\": \"Bicubic\",\n",
    "    \"edsr\": \"EDSR \\cite{lim_enhanced_2017}\",\n",
    "    \"esrgan\": \"ESRGAN \\cite{wang_esrgan_2019}\",\n",
    "    \"dmsp_orig\": \"DMSP \\cite{bigdeli_deep_2017}\",\n",
    "    \"ircnn\": \"IRCNN \\cite{zhang_learning_2017}\",\n",
    "    \"dmsp_paper\": \"DMSP \\cite{bigdeli_deep_2017}\",\n",
    "    \"dpir\": \"DPIR \\cite{zhang_plug-and-play_2021}\",\n",
    "    \"dmsp\": \"DMSP\",\n",
    "    \"hqs\": \"HQS\",\n",
    "}\n",
    "METHOD_MAPPING_BLUR = METHOD_MAPPING.copy()\n",
    "METHOD_MAPPING_BLUR.update(\n",
    "    {\n",
    "        \"edsr\": \"EDSR\\\\bic\\\\ \\cite{lim_enhanced_2017}\",\n",
    "        \"esrgan\": \"ESRGAN\\\\bic\\\\ \\cite{wang_esrgan_2019}\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be90972",
   "metadata": {},
   "outputs": [],
   "source": [
    "hqs_folder = \"results/sisr/hqs/\"\n",
    "dmsp_folder = \"results/sisr/dmsp/\"\n",
    "bicubic_csv = \"results/sisr/bicubic.csv\"\n",
    "edsr_csv = \"results/sisr/edsr.csv\"\n",
    "esrgan_csv = \"results/sisr/esrgan.csv\"\n",
    "dmsppaper_csv = \"results/sisr/dmsp_paper.csv\"\n",
    "dpir_csv = \"results/sisr/dpir.csv\"\n",
    "\n",
    "# HQS\n",
    "df_hqs = load_folder(hqs_folder, MODEL_COL)\n",
    "df_hqs[METHOD_COL] = \"hqs\"\n",
    "\n",
    "# DMSP\n",
    "df_dmsp = load_folder(dmsp_folder, MODEL_COL)\n",
    "df_dmsp[METHOD_COL] = \"dmsp\"\n",
    "\n",
    "# Bicubic\n",
    "df_bicubic = pd.read_csv(bicubic_csv)\n",
    "df_bicubic[METHOD_COL] = \"bicubic\"\n",
    "df_bicubic[MODEL_COL] = \"\"\n",
    "\n",
    "# EDSR\n",
    "df_edsr = pd.read_csv(edsr_csv)\n",
    "df_edsr[METHOD_COL] = \"edsr\"\n",
    "df_edsr[MODEL_COL] = \"\"\n",
    "\n",
    "# ESRGAN\n",
    "df_esrgan = pd.read_csv(esrgan_csv)\n",
    "df_esrgan[METHOD_COL] = \"esrgan\"\n",
    "df_esrgan[MODEL_COL] = \"\"\n",
    "\n",
    "# DMSP Paper\n",
    "df_dmsp_paper = pd.read_csv(dmsppaper_csv)\n",
    "df_dmsp_paper[METHOD_COL] = \"dmsp_paper\"\n",
    "df_dmsp_paper[MODEL_COL] = \"\"\n",
    "\n",
    "# DPIR\n",
    "df_dpir = pd.read_csv(dpir_csv)\n",
    "df_dpir[METHOD_COL] = \"dpir\"\n",
    "df_dpir[MODEL_COL] = \"\"\n",
    "\n",
    "# Combine the datasets\n",
    "df_all = pd.concat([df_hqs, df_dmsp, df_bicubic, df_edsr, df_esrgan, df_dmsp_paper, df_dpir], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the model name mapping\n",
    "with open('models/model_name_mapping.json') as f:\n",
    "    model_mapping = json.load(f)\n",
    "\n",
    "model_mapping = {\n",
    "    \"\": \"\",\n",
    "    **model_mapping\n",
    "}\n",
    "models = list(model_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all[DATASET_COL].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ac98ce",
   "metadata": {},
   "source": [
    "# Main Text Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc30e73",
   "metadata": {},
   "source": [
    "## Bicubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Set5\"\n",
    "downscale = \"bicubic\"\n",
    "metrics = [\"PSNR\", \"LPIPS_ALEX\"]\n",
    "metrics_mapping = {\n",
    "    \"PSNR\": \"PSNR\",\n",
    "    \"LPIPS_ALEX\": \"LPIPS\",\n",
    "}\n",
    "scales = [2, 3, 4, 5]\n",
    "methods = [\"bicubic\", \"edsr\", \"esrgan\", \"dmsp_orig\", \"ircnn\", \"dmsp\", \"hqs\"]\n",
    "models = [\n",
    "    \"\",\n",
    "    \"dcnn_0.05\",\n",
    "    \"drcnn_0.05\",\n",
    "    \"dunet_0.05\",\n",
    "    \"drunet+_0.05\",\n",
    "    \"drunet+_0.0-0.2\",\n",
    "    # \"drugan+-lambda-zero_0.0-0.2\",\n",
    "    \"drugan+_0.0-0.2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f55a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.copy()\n",
    "\n",
    "# Filter only the configured dataset\n",
    "df = df[df[DATASET_COL] == dataset]\n",
    "df = df[df[DOWNSCALE_COL] == downscale]\n",
    "df = df.drop(DATASET_COL, axis=1)\n",
    "df = df.drop(DOWNSCALE_COL, axis=1)\n",
    "\n",
    "# Mean over the images\n",
    "df = df.groupby([METHOD_COL, MODEL_COL, SCALE_COL]).mean()\n",
    "df = df.drop(IMAGE_COL, axis=1)\n",
    "df = df.reset_index()\n",
    "\n",
    "# Combine all metrics in one column\n",
    "df = df.melt(\n",
    "    id_vars=[METHOD_COL, MODEL_COL, SCALE_COL],\n",
    "    var_name=METRIC_COL,\n",
    "    value_name=VALUE_COL,\n",
    ")\n",
    "\n",
    "# Filter metrics and datasets\n",
    "df = df[df[METRIC_COL].isin(metrics)]\n",
    "df = df[df[MODEL_COL].isin(models)]\n",
    "df = df[df[SCALE_COL].isin(scales)]\n",
    "df = df[df[METHOD_COL].isin(methods)]\n",
    "\n",
    "# Sort by Noise, and Metric\n",
    "df = df.sort_values(METRIC_COL, key=sort_key_for(metrics), kind=\"mergesort\")\n",
    "df = df.sort_values(SCALE_COL, kind=\"mergesort\")\n",
    "\n",
    "# Remap metrics\n",
    "df[METRIC_COL] = df[METRIC_COL].map(metrics_mapping)\n",
    "\n",
    "# Noise Level and Metric as columns\n",
    "df = df.set_index([METHOD_COL, MODEL_COL, SCALE_COL, METRIC_COL])\n",
    "df = df.unstack([SCALE_COL, METRIC_COL])\n",
    "\n",
    "df = df.reset_index()\n",
    "df_add = pd.DataFrame(\n",
    "    [\n",
    "        [\"dmsp_orig\", \"\", 35.16, np.nan, 31.38, np.nan, 29.16, np.nan, 27.38, np.nan],\n",
    "        [\"ircnn\", \"\", 35.07, np.nan, 31.26, np.nan, 29.01, np.nan, 27.13, np.nan],\n",
    "    ],\n",
    "    columns=df.columns,\n",
    ")\n",
    "df = pd.concat([df, df_add], axis=0)\n",
    "\n",
    "# Sort and remap models\n",
    "df = df.sort_values(MODEL_COL, key=sort_key_for(models), kind=\"mergesort\")\n",
    "df = df.sort_values(METHOD_COL, key=sort_key_for(methods), kind=\"mergesort\")\n",
    "df[MODEL_COL] = df[MODEL_COL].map(model_mapping)\n",
    "df[METHOD_COL] = df[METHOD_COL].map(METHOD_MAPPING)\n",
    "df = df.set_index([METHOD_COL, MODEL_COL])\n",
    "\n",
    "# Organize the column naming\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df.columns = df.columns.rename([\"Scaling factor \\( s \\)\", \"\"])\n",
    "\n",
    "# Rename model column\n",
    "df.index = df.index.rename([\"Method\", \"\"])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa869479",
   "metadata": {},
   "source": [
    "### Convert to LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_format = \"ll\" + \"C{1}\" * len(df.columns)\n",
    "\n",
    "formatters = [\n",
    "    mark_column_best_formatter(\n",
    "        df, c, mark_max=c[1] == \"PSNR\", num_decimals=2 if c[1] == \"PSNR\" else 4\n",
    "    )\n",
    "    for c in df.columns\n",
    "]\n",
    "\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    latex = df.to_latex(\n",
    "        # float_format=float_format(True),\n",
    "        formatters=formatters,\n",
    "        escape=False,\n",
    "        column_format=column_format,\n",
    "        multicolumn_format=\"c\",\n",
    "        multirow=True,\n",
    "    )\n",
    "# Use tabularx\n",
    "latex = latex.replace(\"\\\\begin{tabular}\", \"\\\\begin{tabularx}{\\\\textwidth}\")\n",
    "latex = latex.replace(\"\\\\end{tabular}\", \"\\\\end{tabularx}\")\n",
    "\n",
    "# Use multicolumn sometimes\n",
    "def to_multicolumn(latex, text, size):\n",
    "    return latex.replace(f\"{text} &\", f\"\\\\multicolumn{{{size}}}{{l}}{{{text}}}\")\n",
    "\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"bicubic\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"edsr\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"esrgan\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"dmsp_orig\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"ircnn\"], 2)\n",
    "latex = to_multicolumn(latex, \"Method\", 2)\n",
    "\n",
    "latex = add_midrule(latex, 9)\n",
    "latex = add_midrule(latex, 12)\n",
    "\n",
    "# print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a981c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEX_TABLE_DIR + \"sisr-bicubic-set5.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac90cc",
   "metadata": {},
   "source": [
    "## Blur Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a68ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Set5\"\n",
    "downscale = {\n",
    "    **{f\"kernel_{i}\": \"isotropic\" for i in [0, 1, 2, 3]},\n",
    "    **{f\"kernel_{i}\": \"anisotropic\" for i in [4, 5, 6, 7]}\n",
    "}\n",
    "metrics = [\"PSNR\", \"LPIPS_ALEX\"]\n",
    "metrics_mapping = {\n",
    "    \"PSNR\": \"PSNR\",\n",
    "    \"LPIPS_ALEX\": \"LPIPS\",\n",
    "}\n",
    "scales = [2, 3]\n",
    "methods = [\"bicubic\", \"edsr\", \"dpir\", \"dmsp\", \"hqs\"]\n",
    "models = [\n",
    "    \"\",\n",
    "    \"dcnn_0.05\",\n",
    "    \"drcnn_0.05\",\n",
    "    \"dunet_0.05\",\n",
    "    \"drunet+_0.05\",\n",
    "    \"drunet+_0.0-0.2\",\n",
    "    # \"drugan+-lambda-zero_0.0-0.2\",\n",
    "    \"drugan+_0.0-0.2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.copy()\n",
    "\n",
    "# Filter only the configured dataset\n",
    "df = df[df[DATASET_COL] == dataset]\n",
    "df = df.drop(DATASET_COL, axis=1)\n",
    "\n",
    "# Map the downscale column\n",
    "df = df[df[DOWNSCALE_COL].isin(downscale)]\n",
    "df[DOWNSCALE_COL] = df[DOWNSCALE_COL].map(downscale)\n",
    "\n",
    "# Mean over the images\n",
    "df = df.groupby([METHOD_COL, MODEL_COL, SCALE_COL, DOWNSCALE_COL]).mean()\n",
    "df = df.drop(IMAGE_COL, axis=1)\n",
    "df = df.reset_index()\n",
    "\n",
    "# Combine all metrics in one column\n",
    "df = df.melt(\n",
    "    id_vars=[METHOD_COL, MODEL_COL, SCALE_COL, DOWNSCALE_COL],\n",
    "    var_name=METRIC_COL,\n",
    "    value_name=VALUE_COL,\n",
    ")\n",
    "\n",
    "# Filter metrics and datasets\n",
    "df = df[df[METRIC_COL].isin(metrics)]\n",
    "df = df[df[MODEL_COL].isin(models)]\n",
    "df = df[df[SCALE_COL].isin(scales)]\n",
    "df = df[df[METHOD_COL].isin(methods)]\n",
    "\n",
    "# Sort by Noise, and Metric\n",
    "df = df.sort_values(METRIC_COL, key=sort_key_for(metrics), kind=\"mergesort\")\n",
    "df = df.sort_values(SCALE_COL, kind=\"mergesort\")\n",
    "df = df.sort_values(\n",
    "    DOWNSCALE_COL, key=sort_key_for(list(downscale.values())), kind=\"mergesort\"\n",
    ")\n",
    "\n",
    "# Remap metrics\n",
    "df[METRIC_COL] = df[METRIC_COL].map(metrics_mapping)\n",
    "\n",
    "# Noise Level and Metric as columns\n",
    "df = df.set_index([METHOD_COL, MODEL_COL, DOWNSCALE_COL, SCALE_COL, METRIC_COL])\n",
    "df = df.unstack([DOWNSCALE_COL, SCALE_COL, METRIC_COL])\n",
    "\n",
    "# Sort and remap models\n",
    "df = df.reset_index()\n",
    "df = df.sort_values(MODEL_COL, key=sort_key_for(models), kind=\"mergesort\")\n",
    "df = df.sort_values(METHOD_COL, key=sort_key_for(methods), kind=\"mergesort\")\n",
    "df[MODEL_COL] = df[MODEL_COL].map(model_mapping)\n",
    "df[METHOD_COL] = df[METHOD_COL].map(METHOD_MAPPING_BLUR)\n",
    "df = df.set_index([METHOD_COL, MODEL_COL])\n",
    "\n",
    "# Organize the column naming\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df.columns = df.columns.rename([\"Blur kernels\", \"Scaling factor \\( s \\)\", \"\"])\n",
    "\n",
    "# Rename model column\n",
    "df.index = df.index.rename([\"Method\", \"\"])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8cc6b",
   "metadata": {},
   "source": [
    "### Convert to LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_format = \"ll\" + \"C{1}\" * len(df.columns)\n",
    "\n",
    "formatters = [\n",
    "    mark_column_best_formatter(\n",
    "        df, c, mark_max=c[2] == \"PSNR\", num_decimals=2 if c[2] == \"PSNR\" else 4\n",
    "    )\n",
    "    for c in df.columns\n",
    "]\n",
    "\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    latex = df.to_latex(\n",
    "        # float_format=float_format(True),\n",
    "        formatters=formatters,\n",
    "        escape=False,\n",
    "        column_format=column_format,\n",
    "        multicolumn_format=\"c\",\n",
    "        multirow=True,\n",
    "    )\n",
    "# Use tabularx\n",
    "latex = latex.replace(\"\\\\begin{tabular}\", \"\\\\begin{tabularx}{\\\\textwidth}\")\n",
    "latex = latex.replace(\"\\\\end{tabular}\", \"\\\\end{tabularx}\")\n",
    "\n",
    "# Use multicolumn sometimes\n",
    "def to_multicolumn(latex, text, size):\n",
    "    return latex.replace(f\"{text} &\", f\"\\\\multicolumn{{{size}}}{{l}}{{{text}}}\")\n",
    "\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING_BLUR[\"bicubic\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING_BLUR[\"edsr\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING_BLUR[\"esrgan\"], 2)\n",
    "latex = to_multicolumn(latex, \"Method\", 2)\n",
    "\n",
    "latex = add_midrule(latex, 10)\n",
    "\n",
    "# print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEX_TABLE_DIR + \"sisr-blur-set5.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348650ba",
   "metadata": {},
   "source": [
    "# Appendix Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59220382",
   "metadata": {},
   "source": [
    "## Bicubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"Set5\": \"Set5\", \"Set14\": \"Set14\", \"CBSD68\": \"CBSD68 \\cite{martin_database_2001}\"}\n",
    "downscale = \"bicubic\"\n",
    "metrics = {\n",
    "    \"PSNR\": \"P\",\n",
    "    \"SSIM\": \"S\",\n",
    "    \"FSIM\": \"F\",\n",
    "    \"LPIPS_ALEX\": \"L\",\n",
    "}\n",
    "scales = [2, 3, 4, 5]\n",
    "methods = [\"bicubic\", \"edsr\", \"esrgan\", \"dmsp\", \"hqs\"]\n",
    "models = [\n",
    "    \"\",\n",
    "    \"dcnn_0.05\",\n",
    "    \"drcnn_0.05\",\n",
    "    \"dunet_0.05\",\n",
    "    \"drunet+_0.05\",\n",
    "    \"drunet+_0.0-0.2\",\n",
    "    # \"drugan+-lambda-zero_0.0-0.2\",\n",
    "    \"drugan+_0.0-0.2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abf464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.copy()\n",
    "\n",
    "df = df[df[DOWNSCALE_COL] == downscale]\n",
    "df = df.drop(DOWNSCALE_COL, axis=1)\n",
    "\n",
    "# Mean over the images\n",
    "df = df.groupby([METHOD_COL, MODEL_COL, SCALE_COL, DATASET_COL]).mean()\n",
    "df = df.drop(IMAGE_COL, axis=1)\n",
    "df = df.reset_index()\n",
    "\n",
    "# Combine all metrics in one column\n",
    "df = df.melt(\n",
    "    id_vars=[METHOD_COL, MODEL_COL, DATASET_COL, SCALE_COL],\n",
    "    var_name=METRIC_COL,\n",
    "    value_name=VALUE_COL,\n",
    ")\n",
    "\n",
    "# Filter metrics and datasets\n",
    "df = df[df[METRIC_COL].isin(metrics)]\n",
    "df = df[df[DATASET_COL].isin(datasets)]\n",
    "df = df[df[METHOD_COL].isin(methods)]\n",
    "df = df[df[MODEL_COL].isin(models)]\n",
    "\n",
    "# Remap names\n",
    "df = df.sort_values(MODEL_COL, key=sort_key_for(models), kind=\"mergesort\")\n",
    "df = df.sort_values(METHOD_COL, key=sort_key_for(methods), kind=\"mergesort\")\n",
    "df[METHOD_COL] = df[METHOD_COL].map(METHOD_MAPPING)\n",
    "df[MODEL_COL] = df[MODEL_COL].map(model_mapping)\n",
    "\n",
    "# Models as columns\n",
    "df = df.set_index([DATASET_COL, SCALE_COL, METRIC_COL, METHOD_COL, MODEL_COL])\n",
    "df = df.unstack([METHOD_COL, MODEL_COL])\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "# Sort by Dataset, Noise, and Metric\n",
    "df = df.sort_values(METRIC_COL, key=sort_key_for(metrics), kind=\"mergesort\")\n",
    "df = df.sort_values(SCALE_COL, kind=\"mergesort\")\n",
    "df = df.sort_values(DATASET_COL, key=sort_key_for(datasets), kind=\"mergesort\")\n",
    "\n",
    "# Rename Dataset, Noise, and Metric\n",
    "df[DATASET_COL] = df[DATASET_COL].map(\n",
    "    lambda x: \"\\rotatebox[origin=c]{90}{\" + datasets[x] + \"}\"\n",
    ")\n",
    "df[SCALE_COL] = df[SCALE_COL].map(\n",
    "    lambda x: \"\\rotatebox[origin=c]{90}{s=\" + str(x) + \" }\"\n",
    ")\n",
    "df[METRIC_COL] = df[METRIC_COL].map(metrics)\n",
    "\n",
    "df = df.set_index([DATASET_COL, SCALE_COL, METRIC_COL])\n",
    "\n",
    "# Update the column index and index\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df.columns = df.columns.rename([\"\", \"\"])\n",
    "df.index = df.index.rename([\"\", \"\", \"\"])\n",
    "\n",
    "# Replace nan\n",
    "df = df.replace(np.nan, \"---\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_format = \"lll|\" + \"C{1}C{1}C{1}|\" + \"C{1}\" * 6 + \"|\" + \"C{1}\" * 2\n",
    "\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    latex = df.to_latex(\n",
    "        float_format=float_format(True),\n",
    "        escape=False,\n",
    "        na_rep=\"---\",\n",
    "        column_format=column_format,\n",
    "        multicolumn_format=\"c\",\n",
    "        multirow=True\n",
    "    )\n",
    "# Use tabularx\n",
    "latex = latex.replace(\"\\\\begin{tabular}\", \"\\\\begin{tabularx}{\\\\textwidth}\")\n",
    "latex = latex.replace(\"\\\\end{tabular}\", \"\\\\end{tabularx}\")\n",
    "\n",
    "# Bug in pandas?? \"&\" Missing in line 4\n",
    "lines = latex.splitlines()\n",
    "lines[3] = \"& & &\" + lines[3]\n",
    "latex = \"\\n\".join(lines)\n",
    "\n",
    "latex = delete_line(latex, 4)\n",
    "\n",
    "# print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEX_TABLE_DIR + \"all_sisr_bicubic.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c7d8e",
   "metadata": {},
   "source": [
    "## Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c44471",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Set5\"\n",
    "downscale = {f\"kernel_{i}\": f\"({chr(97+i)})\" for i in range(8)}\n",
    "metrics = {\n",
    "    \"PSNR\": \"P\",\n",
    "    # \"SSIM\": \"S\",\n",
    "    # \"FSIM\": \"F\",\n",
    "    \"LPIPS_ALEX\": \"L\",\n",
    "}\n",
    "scales = [2, 3, 4]\n",
    "methods = [\"bicubic\", \"edsr\", \"esrgan\", \"dpir\", \"dmsp\", \"hqs\"]\n",
    "models = [\n",
    "    \"\",\n",
    "    \"dcnn_0.05\",\n",
    "    \"drcnn_0.05\",\n",
    "    \"dunet_0.05\",\n",
    "    \"drunet+_0.05\",\n",
    "    \"drunet+_0.0-0.2\",\n",
    "    # \"drugan+-lambda-zero_0.0-0.2\",\n",
    "    \"drugan+_0.0-0.2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd971bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.copy()\n",
    "\n",
    "# Filter only the configured dataset\n",
    "df = df[df[DATASET_COL] == dataset]\n",
    "df = df.drop(DATASET_COL, axis=1)\n",
    "\n",
    "# Map the downscale column\n",
    "df = df[df[DOWNSCALE_COL].isin(downscale)]\n",
    "# df[DOWNSCALE_COL] = df[DOWNSCALE_COL].map(downscale)\n",
    "\n",
    "# Mean over the images\n",
    "df = df.groupby([METHOD_COL, MODEL_COL, DOWNSCALE_COL, SCALE_COL]).mean()\n",
    "df = df.drop(IMAGE_COL, axis=1)\n",
    "df = df.reset_index()\n",
    "\n",
    "# Combine all metrics in one column\n",
    "df = df.melt(\n",
    "    id_vars=[METHOD_COL, MODEL_COL, DOWNSCALE_COL, SCALE_COL],\n",
    "    var_name=METRIC_COL,\n",
    "    value_name=VALUE_COL,\n",
    ")\n",
    "\n",
    "# Filter metrics and datasets\n",
    "df = df[df[METRIC_COL].isin(metrics)]\n",
    "df = df[df[SCALE_COL].isin(scales)]\n",
    "df = df[df[METHOD_COL].isin(methods)]\n",
    "df = df[df[MODEL_COL].isin(models)]\n",
    "\n",
    "# Remap names\n",
    "df = df.sort_values(MODEL_COL, key=sort_key_for(models), kind=\"mergesort\")\n",
    "df = df.sort_values(METHOD_COL, key=sort_key_for(methods), kind=\"mergesort\")\n",
    "df[METHOD_COL] = df[METHOD_COL].map(METHOD_MAPPING_BLUR)\n",
    "df[MODEL_COL] = df[MODEL_COL].map(model_mapping)\n",
    "\n",
    "# Models as columns\n",
    "df = df.set_index([DOWNSCALE_COL, SCALE_COL, METRIC_COL, METHOD_COL, MODEL_COL])\n",
    "df = df.unstack([METHOD_COL, MODEL_COL])\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "# Sort by Dataset, Noise, and Metric\n",
    "df = df.sort_values(METRIC_COL, key=sort_key_for(metrics), kind=\"mergesort\")\n",
    "df = df.sort_values(SCALE_COL, kind=\"mergesort\")\n",
    "df = df.sort_values(DOWNSCALE_COL, kind=\"mergesort\")\n",
    "\n",
    "# Rename Dataset, Noise, and Metric\n",
    "df[DOWNSCALE_COL] = df[DOWNSCALE_COL].map(\n",
    "    lambda x: \"\\rotatebox[origin=c]{90}{\" + downscale[x] + \"}\"\n",
    ")\n",
    "df[SCALE_COL] = df[SCALE_COL].map(\n",
    "    lambda x: \"\\rotatebox[origin=c]{90}{s=\" + str(x) + \" }\"\n",
    ")\n",
    "df[METRIC_COL] = df[METRIC_COL].map(metrics)\n",
    "\n",
    "df = df.set_index([DOWNSCALE_COL, SCALE_COL, METRIC_COL])\n",
    "\n",
    "# Update the column index and index\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df.columns = df.columns.rename([\"\", \"\"])\n",
    "df.index = df.index.rename([\"\", \"\", \"\"])\n",
    "\n",
    "# Replace nan\n",
    "df = df.replace(np.nan, \"---\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98387575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_format = \"lll|\" + \"C{1}C{1}C{1}C{1}|\" + \"C{1}\" * 6 + \"|\" + \"C{1}\" * 2\n",
    "column_format = \"lll|\" + \"C{0.8}\" * 4 + \"|\" + \"C{0.9}\" * 4 + \"C{1}\" * 2 + \"|\" + \"C{1}\" * 2\n",
    "\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    latex = df.to_latex(\n",
    "        float_format=float_format(True),\n",
    "        escape=False,\n",
    "        na_rep=\"---\",\n",
    "        column_format=column_format,\n",
    "        multicolumn_format=\"c\",\n",
    "        multirow=True\n",
    "    )\n",
    "# Use tabularx\n",
    "latex = latex.replace(\"\\\\begin{tabular}\", \"\\\\begin{tabularx}{\\\\textwidth}\")\n",
    "latex = latex.replace(\"\\\\end{tabular}\", \"\\\\end{tabularx}\")\n",
    "\n",
    "# Bug in pandas?? \"&\" Missing in line 4\n",
    "lines = latex.splitlines()\n",
    "lines[3] = \"& & & & \" + lines[3]\n",
    "latex = \"\\n\".join(lines)\n",
    "\n",
    "latex = delete_line(latex, 4)\n",
    "\n",
    "# print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db47f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEX_TABLE_DIR + \"all_sisr_blur.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2a8e9b59df830d48e9f72a82c46cdc1119b3ef257c7d0eadd36484a360f3166"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('masters-proj-eval': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
