{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from notebooks.utils import *\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEX_TABLE_DIR = \"../masters-thesis-tex/tables/\"\n",
    "\n",
    "MODEL_COL = \"model\"\n",
    "METHOD_COL = \"method\"\n",
    "DATASET_COL = \"dataset\"\n",
    "IMAGE_COL = \"image_index\"\n",
    "SCALE_COL = \"scale_factor\"\n",
    "DOWNSCALE_COL = \"downscale_method\"\n",
    "METRIC_COL = \"metric\"\n",
    "VALUE_COL = \"value\"\n",
    "\n",
    "METHOD_MAPPING = {\n",
    "    \"bicubic\": \"Bicubic\",\n",
    "    \"edsr\": \"EDSR\\\\bic\\\\ \\cite{lim_enhanced_2017}\",\n",
    "    \"esrgan\": \"ESRGAN\\\\bic\\\\ \\cite{wang_esrgan_2019}\",\n",
    "    \"edvr\": \"EDVR\\\\bic\\\\ \\cite{wang_edvr_2019}\",\n",
    "    \"lfssr\": \"LFSSR\\\\bic\\\\ \\cite{jin_light_2020}\",\n",
    "    \"dmsp\": \"DMSP\",\n",
    "    \"hqs\": \"HQS\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hqs_folder = \"results/vsr/hqs/\"\n",
    "bicubic_csv = \"results/vsr/bicubic.csv\"\n",
    "edsr_csv = \"results/vsr/edsr.csv\"\n",
    "edvr_csv = \"results/vsr/edvr.csv\"\n",
    "esrgan_csv = \"results/vsr/esrgan.csv\"\n",
    "\n",
    "# HQS\n",
    "df_hqs = load_folder(hqs_folder, MODEL_COL)\n",
    "df_hqs[METHOD_COL] = \"hqs\"\n",
    "\n",
    "# Bicubic\n",
    "df_bicubic = pd.read_csv(bicubic_csv)\n",
    "df_bicubic[METHOD_COL] = \"bicubic\"\n",
    "df_bicubic[MODEL_COL] = \"\"\n",
    "\n",
    "# EDSR\n",
    "df_edsr = pd.read_csv(edsr_csv)\n",
    "df_edsr[METHOD_COL] = \"edsr\"\n",
    "df_edsr[MODEL_COL] = \"\"\n",
    "\n",
    "# EDVR\n",
    "df_edvr = pd.read_csv(edvr_csv)\n",
    "df_edvr[METHOD_COL] = \"edvr\"\n",
    "df_edvr[MODEL_COL] = \"\"\n",
    "\n",
    "# ESRGAN\n",
    "df_esrgan = pd.read_csv(esrgan_csv)\n",
    "df_esrgan[METHOD_COL] = \"esrgan\"\n",
    "df_esrgan[MODEL_COL] = \"\"\n",
    "\n",
    "# Combine the datasets\n",
    "df_all = pd.concat([df_hqs, df_bicubic, df_edsr, df_edvr, df_esrgan], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the model name mapping\n",
    "with open('models/model_name_mapping.json') as f:\n",
    "    model_mapping = json.load(f)\n",
    "\n",
    "model_mapping = {\n",
    "    \"\": \"\",\n",
    "    **model_mapping\n",
    "}\n",
    "models = list(model_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all[DATASET_COL].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Text Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Vid4\"\n",
    "downscale = {\n",
    "    \"bicubic\": \"bicubic\",\n",
    "    **{f\"kernel_{i}\": \"isotropic blur\" for i in [0, 1, 2, 3]},\n",
    "    **{f\"kernel_{i}\": \"anisotropic blur\" for i in [4, 5, 6, 7]},\n",
    "}\n",
    "metrics = [\"PSNR\", \"LPIPS_ALEX\"]\n",
    "metrics_mapping = {\n",
    "    \"PSNR\": \"PSNR\",\n",
    "    \"LPIPS_ALEX\": \"LPIPS\",\n",
    "}\n",
    "scales = [\"bicubic2\", \"bicubic4\", \"isotropic blur4\", \"anisotropic blur4\"]\n",
    "methods = [\"bicubic\", \"edsr\", \"esrgan\", \"edvr\", \"dmsp\", \"hqs\"]\n",
    "models = [\n",
    "    \"\",\n",
    "    \"dcnn_0.05\",\n",
    "    \"drcnn_0.05\",\n",
    "    \"dunet_0.05\",\n",
    "    \"drunet+_0.05\",\n",
    "    \"drunet+_0.0-0.2\",\n",
    "    # \"drugan+-lambda-zero_0.0-0.2\",\n",
    "    \"drugan+_0.0-0.2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.copy()\n",
    "\n",
    "# Filter only the configured dataset\n",
    "df = df[df[DATASET_COL] == dataset]\n",
    "df = df.drop(DATASET_COL, axis=1)\n",
    "\n",
    "# Map the downscale column\n",
    "df = df[df[DOWNSCALE_COL].isin(downscale)]\n",
    "df[DOWNSCALE_COL] = df[DOWNSCALE_COL].map(downscale)\n",
    "\n",
    "# Mean over the images\n",
    "df = df.groupby([METHOD_COL, MODEL_COL, SCALE_COL, DOWNSCALE_COL]).mean()\n",
    "df = df.drop(IMAGE_COL, axis=1)\n",
    "df = df.reset_index()\n",
    "\n",
    "# Combine all metrics in one column\n",
    "df = df.melt(\n",
    "    id_vars=[METHOD_COL, MODEL_COL, SCALE_COL, DOWNSCALE_COL],\n",
    "    var_name=METRIC_COL,\n",
    "    value_name=VALUE_COL,\n",
    ")\n",
    "\n",
    "# Filter metrics and datasets\n",
    "df = df[df[METRIC_COL].isin(metrics)]\n",
    "df = df[df[MODEL_COL].isin(models)]\n",
    "df = df[(df[DOWNSCALE_COL] + df[SCALE_COL].astype(str)).isin(scales)]\n",
    "df = df[df[METHOD_COL].isin(methods)]\n",
    "\n",
    "# Sort by Noise, and Metric\n",
    "df = df.sort_values(METRIC_COL, key=sort_key_for(metrics), kind=\"mergesort\")\n",
    "df = df.sort_values(SCALE_COL, kind=\"mergesort\")\n",
    "df = df.sort_values(\n",
    "    DOWNSCALE_COL, key=sort_key_for(list(downscale.values())), kind=\"mergesort\"\n",
    ")\n",
    "\n",
    "# Remap metrics\n",
    "df[METRIC_COL] = df[METRIC_COL].map(metrics_mapping)\n",
    "\n",
    "# Noise Level and Metric as columns\n",
    "df = df.set_index([METHOD_COL, MODEL_COL, DOWNSCALE_COL, SCALE_COL, METRIC_COL])\n",
    "df = df.unstack([DOWNSCALE_COL, SCALE_COL, METRIC_COL])\n",
    "\n",
    "# Sort and remap models\n",
    "df = df.reset_index()\n",
    "df = df.sort_values(MODEL_COL, key=sort_key_for(models), kind=\"mergesort\")\n",
    "df = df.sort_values(METHOD_COL, key=sort_key_for(methods), kind=\"mergesort\")\n",
    "df[MODEL_COL] = df[MODEL_COL].map(model_mapping)\n",
    "df[METHOD_COL] = df[METHOD_COL].map(METHOD_MAPPING)\n",
    "df = df.set_index([METHOD_COL, MODEL_COL])\n",
    "\n",
    "# Organize the column naming\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df.columns = df.columns.rename([\"Downscaling\", \"Scaling factor \\( s \\)\", \"\"])\n",
    "\n",
    "# Rename model column\n",
    "df.index = df.index.rename([\"Method\", \"\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_format = \"ll\" + \"C{1}\" * len(df.columns)\n",
    "\n",
    "\n",
    "formatters = [\n",
    "    mark_column_best_formatter(\n",
    "        df, c, mark_max=c[2] == \"PSNR\", num_decimals=2 if c[1] == \"PSNR\" else 4\n",
    "    )\n",
    "    for c in df.columns\n",
    "]\n",
    "\n",
    "# with pd.option_context(\"max_colwidth\", 1000):\n",
    "latex = df.to_latex(\n",
    "    formatters=formatters,\n",
    "    escape=False,\n",
    "    column_format=column_format,\n",
    "    multicolumn_format=\"c\",\n",
    "    multirow=True,\n",
    ")\n",
    "# Use tabularx\n",
    "latex = latex.replace(\"\\\\begin{tabular}\", \"\\\\begin{tabularx}{\\\\textwidth}\")\n",
    "latex = latex.replace(\"\\\\end{tabular}\", \"\\\\end{tabularx}\")\n",
    "\n",
    "# Use multicolumn sometimes\n",
    "def to_multicolumn(latex, text, size):\n",
    "    return latex.replace(f\"{text} &\", f\"\\\\multicolumn{{{size}}}{{l}}{{{text}}}\")\n",
    "\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"bicubic\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"edsr\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"esrgan\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"edvr\"], 2)\n",
    "latex = to_multicolumn(latex, METHOD_MAPPING[\"lfssr\"], 2)\n",
    "latex = to_multicolumn(latex, \"Method\", 2)\n",
    "\n",
    "\n",
    "latex = add_midrule(latex, 11)\n",
    "\n",
    "# print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEX_TABLE_DIR + \"vsr-vid4.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Vid4\"\n",
    "downscale = {\n",
    "    \"bicubic\": \"bicubic\",\n",
    "    **{f\"kernel_{i}\": f\"({chr(97+i)})\" for i in range(8)},\n",
    "}\n",
    "metrics = {\n",
    "    \"PSNR\": \"P\",\n",
    "    \"SSIM\": \"S\",\n",
    "    \"FSIM\": \"F\",\n",
    "    \"LPIPS_ALEX\": \"L\",\n",
    "}\n",
    "metrics_bicubic = [\"PSNR\", \"SSIM\", \"FSIM\", \"LPIPS_ALEX\"]\n",
    "metrics_blur = [\"PSNR\", \"LPIPS_ALEX\"]\n",
    "scales_bicubic = [2, 3, 4, 5]\n",
    "scales_blur = [2, 3, 4]\n",
    "# methods = [\"bicubic\", \"edsr\", \"esrgan\", \"dmsp\", \"hqs\"]\n",
    "methods = [\"bicubic\", \"edsr\", \"esrgan\", \"edvr\", \"dmsp\", \"hqs\"]\n",
    "models = [\n",
    "    \"\",\n",
    "    \"dcnn_0.05\",\n",
    "    \"drcnn_0.05\",\n",
    "    \"dunet_0.05\",\n",
    "    \"drunet+_0.05\",\n",
    "    \"drunet+_0.0-0.2\",\n",
    "    # \"drugan+-lambda-zero_0.0-0.2\",\n",
    "    \"drugan+_0.0-0.2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.copy()\n",
    "\n",
    "# Filter only the configured dataset\n",
    "df = df[df[DATASET_COL] == dataset]\n",
    "df = df.drop(DATASET_COL, axis=1)\n",
    "\n",
    "# Map the downscale column\n",
    "df = df[df[DOWNSCALE_COL].isin(downscale)]\n",
    "# df[DOWNSCALE_COL] = df[DOWNSCALE_COL].map(downscale)\n",
    "\n",
    "# Mean over the images\n",
    "df = df.groupby([METHOD_COL, MODEL_COL, DOWNSCALE_COL, SCALE_COL]).mean()\n",
    "df = df.drop(IMAGE_COL, axis=1)\n",
    "df = df.reset_index()\n",
    "\n",
    "# Combine all metrics in one column\n",
    "df = df.melt(\n",
    "    id_vars=[METHOD_COL, MODEL_COL, DOWNSCALE_COL, SCALE_COL],\n",
    "    var_name=METRIC_COL,\n",
    "    value_name=VALUE_COL,\n",
    ")\n",
    "\n",
    "# Filter metrics and datasets\n",
    "df = df[\n",
    "    ((df[DOWNSCALE_COL] == \"bicubic\") & df[METRIC_COL].isin(metrics_bicubic))\n",
    "    | (df[DOWNSCALE_COL].str.startswith(\"kernel_\") & df[METRIC_COL].isin(metrics_blur))\n",
    "]\n",
    "df = df[# df[SCALE_COL].isin(scales)]\n",
    "    ((df[DOWNSCALE_COL] == \"bicubic\") & df[SCALE_COL].isin(scales_bicubic))\n",
    "    | (df[DOWNSCALE_COL].str.startswith(\"kernel_\") & df[SCALE_COL].isin(scales_blur))\n",
    "]\n",
    "df = df[df[METHOD_COL].isin(methods)]\n",
    "df = df[df[MODEL_COL].isin(models)]\n",
    "\n",
    "# Remap names\n",
    "df = df.sort_values(MODEL_COL, key=sort_key_for(models), kind=\"mergesort\")\n",
    "df = df.sort_values(METHOD_COL, key=sort_key_for(methods), kind=\"mergesort\")\n",
    "df[METHOD_COL] = df[METHOD_COL].map(METHOD_MAPPING)\n",
    "df[MODEL_COL] = df[MODEL_COL].map(model_mapping)\n",
    "\n",
    "# Models as columns\n",
    "df = df.set_index([DOWNSCALE_COL, SCALE_COL, METRIC_COL, METHOD_COL, MODEL_COL])\n",
    "df = df.unstack([METHOD_COL, MODEL_COL])\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "# Sort by Dataset, Noise, and Metric\n",
    "df = df.sort_values(METRIC_COL, key=sort_key_for(metrics), kind=\"mergesort\")\n",
    "df = df.sort_values(SCALE_COL, kind=\"mergesort\")\n",
    "df = df.sort_values(DOWNSCALE_COL, kind=\"mergesort\")\n",
    "\n",
    "# Rename Dataset, Noise, and Metric\n",
    "df[DOWNSCALE_COL] = df[DOWNSCALE_COL].map(\n",
    "    lambda x: \"\\rotatebox[origin=c]{90}{\" + downscale[x] + \"}\"\n",
    ")\n",
    "df[SCALE_COL] = df[SCALE_COL].map(\n",
    "    lambda x: \"\\rotatebox[origin=c]{90}{s=\" + str(x) + \" }\"\n",
    ")\n",
    "df[METRIC_COL] = df[METRIC_COL].map(metrics)\n",
    "\n",
    "df = df.set_index([DOWNSCALE_COL, SCALE_COL, METRIC_COL])\n",
    "\n",
    "# Update the column index and index\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df.columns = df.columns.rename([\"\", \"\"])\n",
    "df.index = df.index.rename([\"\", \"\", \"\"])\n",
    "\n",
    "# Replace nan\n",
    "df = df.replace(np.nan, \"---\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_format = \"lll|\" + \"C{1}\" * 4 + \"|\" + \"C{1}\" * 2\n",
    "\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    latex = df.to_latex(\n",
    "        float_format=float_format(True),\n",
    "        escape=False,\n",
    "        na_rep=\"---\",\n",
    "        column_format=column_format,\n",
    "        multicolumn_format=\"c\",\n",
    "        multirow=True,\n",
    "    )\n",
    "# Use tabularx\n",
    "latex = latex.replace(\"\\\\begin{tabular}\", \"\\\\begin{tabularx}{\\\\textwidth}\")\n",
    "latex = latex.replace(\"\\\\end{tabular}\", \"\\\\end{tabularx}\")\n",
    "\n",
    "# Bug in pandas?? \"&\" Missing in line 4\n",
    "lines = latex.splitlines()\n",
    "lines[3] = \"& & & &\" + lines[3]\n",
    "latex = \"\\n\".join(lines)\n",
    "\n",
    "latex = delete_line(latex, 4)\n",
    "\n",
    "# print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEX_TABLE_DIR + \"all_vsr.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2a8e9b59df830d48e9f72a82c46cdc1119b3ef257c7d0eadd36484a360f3166"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('masters-proj-eval': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
